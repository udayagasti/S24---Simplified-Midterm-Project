{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bf1e9e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile inference.py\n",
    "import joblib\n",
    "import os\n",
    "import json\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from sklearn.feature_extraction.text import HashingVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import pickle\n",
    "import boto3\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Deserialize fitted model\n",
    "\"\"\"\n",
    "def model_fn(model_dir):\n",
    "    # Load the trained model from the model directory\n",
    "    model = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return model\n",
    "\n",
    "\"\"\"\n",
    "input_fn\n",
    "    request_body: The body of the request sent to the model.\n",
    "    request_content_type: (string) specifies the format/variable type of the request\n",
    "\"\"\"\n",
    "def input_fn(request_body, request_content_type):\n",
    "    if request_content_type == 'application/json':\n",
    "        # Parse the input data if it's in JSON format\n",
    "        input_data = json.loads(request_body)\n",
    "        return input_data\n",
    "    else:\n",
    "        raise ValueError(\"This model only supports application/json input\")\n",
    "\n",
    "\"\"\"\n",
    "predict_fn\n",
    "    input_data: returned data from input_fn above\n",
    "    model (sklearn model) returned model loaded from model_fn above\n",
    "\"\"\"\n",
    "def predict_fn(input_data, model):\n",
    "    # Process the input data if necessary\n",
    "    processed_data = process_input(input_data)\n",
    "    # Make predictions using the model\n",
    "    predictions = model.predict(processed_data)\n",
    "    return predictions\n",
    "\n",
    "def process_input(input_data):\n",
    "    # Extract necessary data from the input dictionary\n",
    "    NgramFeaturesList_pred = np.array(input_data['NgramFeaturesList_pred'])\n",
    "    importsCorpus_pred = input_data['importsCorpus_pred']\n",
    "    sectionNames_pred = input_data['sectionNames_pred']\n",
    "    numSections_pred = int(input_data['numSections_pred'])\n",
    "\n",
    "    # Load featurizers\n",
    "    imports_featurizer = joblib.load(os.path.join(\"opt/ml/model\", \"imports_featurizer.pkl\"))\n",
    "    section_names_featurizer = joblib.load(os.path.join(\"opt/ml/model\", \"section_names_featurizer.pkl\"))\n",
    "    \n",
    "    # Transform text features\n",
    "    importsCorpus_pred_transformed = imports_featurizer.transform([importsCorpus_pred])\n",
    "    sectionNames_pred_transformed = section_names_featurizer.transform([sectionNames_pred])\n",
    "\n",
    "    # Concatenate features into a single sparse matrix\n",
    "    processed_data = hstack([csr_matrix(NgramFeaturesList_pred),\n",
    "                             importsCorpus_pred_transformed,\n",
    "                             sectionNames_pred_transformed,\n",
    "                             csr_matrix([numSections_pred]).transpose()])\n",
    "    return processed_data\n",
    "\n",
    "\"\"\"\n",
    "output_fn\n",
    "    prediction: the returned value from predict_fn above\n",
    "    content_type: the content type the endpoint expects to be returned. Ex: JSON, string\n",
    "\"\"\"\n",
    "def output_fn(prediction, content_type):\n",
    "    # Prepare the output in JSON format\n",
    "    res = int(prediction[0])\n",
    "    respJSON = {'Output': res}\n",
    "    return respJSON\n",
    "\n",
    "\"\"\"if __name__ == '__main__':\n",
    "    # Example usage for testing the functions individually\n",
    "    predict_fn({'NgramFeaturesList_pred': [[24183, 3382, 304, 17, 923, 636, 358, 275, 128, 635, 358, 613, 389, 384, 448, 12, 380, 170, 307, 122, 224, 203, 51, 338, 521, 111, 395, 215, 175, 419, 264, 397, 287, 106, 487, 236, 16, 277, 459, 594, 469, 241, 155, 163, 158, 230, 215, 443, 80, 46, 44, 216, 68, 42, 36, 48, 161, 29, 240, 145, 139, 52, 20, 75, 99, 33, 224, 161, 38, 226, 729, 139, 27, 168, 19, 68, 269, 271, 236, 33, 197, 207, 337, 1114, 126, 111, 255, 175, 47, 46, 60, 318, 129, 79, 16, 223, 162, 79, 15, 157]],\n",
    " 'importsCorpus_pred': \"kernel32 shlwapi ole32 shell32 user32\",\n",
    " 'sectionNames_pred': \".text .rdata .data .rsrc .reloc\",\n",
    " 'numSections_pred': \"5\"}, model_fn(\"\"))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31a1a088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "joblib\n",
    "scipy\n",
    "numpy\n",
    "scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e372328",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p opt/ml/model  \n",
    "!cp model.joblib opt/ml/model/model.joblib\n",
    "!cp imports_featurizer.pkl opt/ml/model/imports_featurizer.pkl\n",
    "!cp section_names_featurizer.pkl opt/ml/model/section_names_featurizer.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d7a0991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.joblib\n",
      "inference.py\n",
      "imports_featurizer.pkl\n",
      "section_names_featurizer.pkl\n",
      "requirements.txt\n",
      "opt/\n",
      "opt/ml/\n",
      "opt/ml/model/\n",
      "opt/ml/model/imports_featurizer.pkl\n",
      "opt/ml/model/model.pkl\n",
      "opt/ml/model/model.joblib\n",
      "opt/ml/model/section_names_featurizer.pkl\n"
     ]
    }
   ],
   "source": [
    "!tar -cvpzf model.tar.gz model.joblib inference.py imports_featurizer.pkl section_names_featurizer.pkl requirements.txt opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c43a7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import joblib\n",
    "import pickle\n",
    "import tarfile\n",
    "import sagemaker\n",
    "from sagemaker.estimator import Estimator\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa881c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-east-1\n"
     ]
    }
   ],
   "source": [
    "# Setting up Boto3 clients and resources\n",
    "client = boto3.client(service_name=\"sagemaker\")\n",
    "runtime = boto3.client(service_name=\"sagemaker-runtime\")\n",
    "boto_session = boto3.session.Session()\n",
    "s3 = boto_session.resource('s3')\n",
    "\n",
    "# Retrieving the AWS region\n",
    "region = boto_session.region_name\n",
    "print(region)\n",
    "\n",
    "# Creating a SageMaker session\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# Defining the IAM role for SageMaker\n",
    "role = \"arn:aws:iam::533267294611:role/LabRole\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86832281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the URI for the Scikit-learn container image\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"sklearn\",          # Specify the framework as Scikit-learn\n",
    "    region=region,                # Specify the AWS region\n",
    "    version=\"1.2-1\",              # Specify the version of Scikit-learn\n",
    "    py_version=\"py3\",             # Specify the Python version\n",
    "    instance_type=\"ml.t2.medium\", # Specify the instance type for hosting the model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fe28bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-east-1-533267294611\n"
     ]
    }
   ],
   "source": [
    "# Get the default bucket for storing model artifacts\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "print(default_bucket)\n",
    "\n",
    "# Specify the path for uploading model artifacts to the bucket\n",
    "model_artifacts = f\"s3://{default_bucket}/model.tar.gz\"\n",
    "\n",
    "# Upload the model artifacts (e.g., 'model.tar.gz') to the specified bucket\n",
    "response = s3.meta.client.upload_file('model.tar.gz', default_bucket, 'model.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1eefa790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: sklearn-test2024-04-03-02-48-21\n",
      "Model Arn: arn:aws:sagemaker:us-east-1:533267294611:model/sklearn-test2024-04-03-02-48-21\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Model Creation\n",
    "\n",
    "# Generate a unique model name with a timestamp\n",
    "model_name = \"sklearn-test-\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(\"Model name: \" + model_name)\n",
    "\n",
    "# Create a model using the SageMaker client\n",
    "create_model_response = client.create_model(\n",
    "    ModelName=model_name,                            # Specify the name for the model\n",
    "    Containers=[                                     # Specify container configuration\n",
    "        {\n",
    "            \"Image\": image_uri,                      # Specify the container image URI\n",
    "            \"Mode\": \"SingleModel\",                   # Specify the mode as SingleModel\n",
    "            \"ModelDataUrl\": model_artifacts,         # Specify the location of model artifacts\n",
    "            \"Environment\": {                         # Specify environment variables\n",
    "                'SAGEMAKER_SUBMIT_DIRECTORY': model_artifacts,\n",
    "                'SAGEMAKER_PROGRAM': 'inference.py'\n",
    "            } \n",
    "        }\n",
    "    ],\n",
    "    ExecutionRoleArn=role,                           # Specify the execution role ARN\n",
    ")\n",
    "\n",
    "# Print the model ARN\n",
    "print(\"Model Arn: \" + create_model_response[\"ModelArn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc79699b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Configuration Arn: arn:aws:sagemaker:us-east-1:533267294611:endpoint-config/sklearn-epc2024-04-03-02-48-25\n"
     ]
    }
   ],
   "source": [
    "# Step 2: EPC Creation\n",
    "\n",
    "# Generate a unique endpoint configuration name with a timestamp\n",
    "sklearn_epc_name = \"sklearn-epc-\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "# Create an endpoint configuration using the SageMaker client\n",
    "endpoint_config_response = client.create_endpoint_config(\n",
    "    EndpointConfigName=sklearn_epc_name,    # Specify the name for the endpoint configuration\n",
    "    ProductionVariants=[                    # Specify production variants\n",
    "        {\n",
    "            \"VariantName\": \"sklearnvariant\",            # Specify variant name\n",
    "            \"ModelName\": model_name,                     # Specify the model name\n",
    "            \"InstanceType\": \"ml.t2.medium\",              # Specify the instance type\n",
    "            \"InitialInstanceCount\": 1                     # Specify the initial instance count\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Print the endpoint configuration ARN\n",
    "print(\"Endpoint Configuration Arn: \" + endpoint_config_response[\"EndpointConfigArn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c15aea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Arn: arn:aws:sagemaker:us-east-1:533267294611:endpoint/sklearn-local-ep2024-04-03-02-48-26\n"
     ]
    }
   ],
   "source": [
    "# Step 3: EP Creation\n",
    "\n",
    "# Generate a unique endpoint name with a timestamp\n",
    "endpoint_name = \"sklearn-local-ep-\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "# Create an endpoint using the SageMaker client\n",
    "create_endpoint_response = client.create_endpoint(\n",
    "    EndpointName=endpoint_name,            # Specify the name for the endpoint\n",
    "    EndpointConfigName=sklearn_epc_name,  # Specify the endpoint configuration name\n",
    ")\n",
    "\n",
    "# Print the endpoint ARN\n",
    "print(\"Endpoint Arn: \" + create_endpoint_response[\"EndpointArn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "228655e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "InService\n",
      "{'EndpointName': 'sklearn-local-ep2024-04-03-02-48-26', 'EndpointArn': 'arn:aws:sagemaker:us-east-1:533267294611:endpoint/sklearn-local-ep2024-04-03-02-48-26', 'EndpointConfigName': 'sklearn-epc2024-04-03-02-48-25', 'ProductionVariants': [{'VariantName': 'sklearnvariant', 'DeployedImages': [{'SpecifiedImage': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:1.2-1-cpu-py3', 'ResolvedImage': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn@sha256:0381fc23e5c6ee7a0a944240dbaf6041688cb1e439af23e0c930da072ac9e971', 'ResolutionTime': datetime.datetime(2024, 4, 3, 2, 48, 28, 10000, tzinfo=tzlocal())}], 'CurrentWeight': 1.0, 'DesiredWeight': 1.0, 'CurrentInstanceCount': 1, 'DesiredInstanceCount': 1}], 'EndpointStatus': 'InService', 'CreationTime': datetime.datetime(2024, 4, 3, 2, 48, 27, 154000, tzinfo=tzlocal()), 'LastModifiedTime': datetime.datetime(2024, 4, 3, 2, 53, 23, 442000, tzinfo=tzlocal()), 'ResponseMetadata': {'RequestId': '77c17d0a-2066-481b-9392-a4521ea308ef', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '77c17d0a-2066-481b-9392-a4521ea308ef', 'content-type': 'application/x-amz-json-1.1', 'content-length': '766', 'date': 'Wed, 03 Apr 2024 02:53:31 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Monitor creation\n",
    "\n",
    "# Describe the endpoint to monitor its status\n",
    "describe_endpoint_response = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "\n",
    "# Check if the endpoint status is \"Creating\"\n",
    "while describe_endpoint_response[\"EndpointStatus\"] == \"Creating\":\n",
    "    # Wait for 15 seconds\n",
    "    time.sleep(15)\n",
    "    # Describe the endpoint again to check its status\n",
    "    describe_endpoint_response = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    # Print the current status of the endpoint\n",
    "    print(describe_endpoint_response[\"EndpointStatus\"])\n",
    "\n",
    "# Once the endpoint status is not \"Creating\", print the final response\n",
    "print(describe_endpoint_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f77454",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
